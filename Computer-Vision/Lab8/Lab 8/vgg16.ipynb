{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "M-ptCCOqnI3G",
    "colab_type": "code",
    "outputId": "994b24b0-4363-4964-ba95-ebff9406d21c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.554607537857E12,
     "user_tz": -300.0,
     "elapsed": 28608.0,
     "user": {
      "displayName": "Mujtaba Faizi",
      "photoUrl": "",
      "userId": "00329453422207437123"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)\n",
    "!ls \"/content/drive/My Drive/Colab Notebooks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDsSPuZboO5Y",
    "colab_type": "code",
    "outputId": "47736f37-85fc-4551-f4f6-61fca9653fdd",
    "executionInfo": {
     "status": "error",
     "timestamp": 1.554611061865E12,
     "user_tz": -300.0,
     "elapsed": 26008.0,
     "user": {
      "displayName": "Mujtaba Faizi",
      "photoUrl": "",
      "userId": "00329453422207437123"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469.0
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-86b0b5535232>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'flatten'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    325\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected min_ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer flatten: expected min_ndim=3, found ndim=2"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras import Model\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy\n",
    "\n",
    "model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "last = model.output\n",
    "x = Flatten(name='flatten')(last)\n",
    "x = Dense(1000, activation='relu')(x)\n",
    "preds = Dense(1, activation='softmax')(x)\n",
    "model = Model(model.input, preds)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "#image augmentations\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   validation_split=0.2)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\"/content/drive/My Drive/Colab Notebooks/data/train\",\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary',\n",
    "                                                 subset = 'training')\n",
    "testing_set = train_datagen.flow_from_directory(\"/content/drive/My Drive/Colab Notebooks/data/train\",\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary',\n",
    "                                                 subset='validation')\n",
    "\n",
    "validation_set = test_datagen.flow_from_directory(\"/content/drive/My Drive/Colab Notebooks/data/validation\",\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(training_set,\n",
    "    epochs = 12,\n",
    "    validation_data = testing_set,\n",
    "    steps_per_epoch=1,\n",
    "    validation_steps=1,\n",
    "    verbose=1)\n",
    "\n",
    "# Save the weights\n",
    "model.save_weights('/content/drive/My Drive/Colab Notebooks/VGG_model_weights.h5')\n",
    "\n",
    "# Save the model architecture\n",
    "with open('/content/drive/My Drive/Colab Notebooks/VGG_model.json', 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "\n",
    "score = model.evaluate_generator(testing_set, steps=1)\n",
    "\n",
    "# # Model reconstruction from JSON file\n",
    "# with open('LSTM_model.json', 'r') as f:\n",
    "#     model = model_from_json(f.read())\n",
    "#\n",
    "# # Load weights into the new model\n",
    "# model.load_weights('LSTM_model_weights.h5')\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "img1 = cv2.imread('/content/drive/My Drive/Colab Notebooks/dog1.jpg')\n",
    "img1 = cv2.resize(img1, (224,224))\n",
    "# img1 = img1.reshape(1,224,224,3)\n",
    "img2 = cv2.imread('/content/drive/My Drive/Colab Notebooks/cat1.jpg')\n",
    "img2 = cv2.resize(img2, (224,224))\n",
    "img3 = cv2.imread('/content/drive/My Drive/Colab Notebooks/dog2.jpg')\n",
    "img3 = cv2.resize(img3, (224,224))\n",
    "img4 = cv2.imread('/content/drive/My Drive/Colab Notebooks/cat2.jpg')\n",
    "img4 = cv2.resize(img4, (224,224))\n",
    "img=[img1,img2,img3,img4]\n",
    "img=numpy.array(img)\n",
    "\n",
    "pred = model.predict(img)\n",
    "list=[]\n",
    "for a in pred:\n",
    "    if a>0.5:\n",
    "        list.append(\"dog\")\n",
    "    else:\n",
    "        list.append(\"cat\")\n",
    "\n",
    "f, axarr = plt.subplots(2,2)\n",
    "axarr[0,0].imshow(img1)\n",
    "axarr[0,0].set_title(\"This is a \"+list[0])\n",
    "axarr[0,1].imshow(img2)\n",
    "axarr[0,1].set_title(\"This is a \"+list[1])\n",
    "axarr[1,0].imshow(img3)\n",
    "axarr[1,0].set_title(\"This is a \"+list[2])\n",
    "axarr[1,1].imshow(img4)\n",
    "axarr[1,1].set_title(\"This is a \"+list[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "4G0ZeslLoDok",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled",
   "version": "0.3.2",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
